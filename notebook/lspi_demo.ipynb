{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- does lspi work?\n",
    "    - linear yes...\n",
    "    - rbf no...\n",
    "- how does linear lspi behave according to D? \n",
    "    - only optimal - yes\n",
    "    - noisy optimal\n",
    "    - completely random\n",
    "- how does rbf lspi behave according to D? \n",
    "    - only optimal\n",
    "    - noisy optimal\n",
    "    - completely random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import sys\n",
    "import os\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.insert(0, \"../\")\n",
    "\n",
    "from algo.lstd import LSTDQ, LSTDMu, LSPI\n",
    "from algo.policy import RandomPolicy2, LinearQ2\n",
    "from env.simulator import * \n",
    "from util.plotting import *\n",
    "from util.basis import *\n",
    "from algo.fa import LinearQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env_id = \"MountainCar-v0\"\n",
    "env = gym.envs.make(env_id)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "# discrete action\n",
    "action_dim = 1\n",
    "n_action = env.action_space.n\n",
    "sim = Simulator(env, state_dim=state_dim, action_dim=action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear basis func\n",
    "p_linear = 3\n",
    "q_linear = 3\n",
    "phi_linear = simple_phi\n",
    "psi_linear = phi_linear\n",
    "p_rbf = 100\n",
    "q_rbf = 100\n",
    "phi_rbf = get_rbf_basis(env, n_component=50)\n",
    "psi_rbf = phi_rbf\n",
    "p = p_linear\n",
    "q = q_linear\n",
    "phi = phi_linear\n",
    "psi = psi_linear\n",
    "precision = 0.1\n",
    "eps = 0.001\n",
    "gamma = 1.0\n",
    "action_list = range(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhfromkorea/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(57)predict()\n",
      "-> if a is None:\n",
      "(Pdb) l\n",
      " 52  \t        featurized = self.featurizer.transform(scaled)\n",
      " 53  \t        return featurized[0]\n",
      " 54  \t\n",
      " 55  \t    def predict(self, s, a=None):\n",
      " 56  \t        import pdb;pdb.set_trace()\n",
      " 57  ->\t        if a is None:\n",
      " 58  \t            Q = []\n",
      " 59  \t            for m, a in zip(self.models, range(self._env.action_space.n)):\n",
      " 60  \t                #features = self._phi(s, a)[0]\n",
      " 61  \t\n",
      " 62  \t                features = self.featurize_state(s, a)\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(58)predict()\n",
      "-> Q = []\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(59)predict()\n",
      "-> for m, a in zip(self.models, range(self._env.action_space.n)):\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(62)predict()\n",
      "-> features = self.featurize_state(s, a)\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(66)predict()\n",
      "-> Q.append(m.predict([features])[0])\n",
      "(Pdb) features.shape\n",
      "(100,)\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(59)predict()\n",
      "-> for m, a in zip(self.models, range(self._env.action_space.n)):\n",
      "(Pdb) Q\n",
      "[0.0]\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(62)predict()\n",
      "-> features = self.featurize_state(s, a)\n",
      "(Pdb) n\n",
      "> /home/dhfromkorea/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py(66)predict()\n",
      "-> Q.append(m.predict([features])[0])\n",
      "(Pdb) quit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3a5c5fba388f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                       gamma=gamma)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpi_expert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdp_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#plotting.plot_cost_to_go_mountain_car(env, pi_expert._estimator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_episode_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, reward_fn)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;31m#action = pi.choose_action(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py\u001b[0m in \u001b[0;36mpolicy_fn\u001b[0;34m(observation)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mbest_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_action\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, s, a)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m#print(\"features dh\", features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m#print(\"features orig\", features_orig)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/master_personal/code_dh/scripts/harvard/courses/mighty-rl/algo/fa.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, s, a)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m#print(\"features dh\", features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m#print(\"features orig\", features_orig)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# one reason: basis function includes action (remove... but how?)\n",
    "# swapping with the original code copy paste\n",
    "# estimator update?\n",
    "mdp_solver = LinearQ3(env=env,\n",
    "                      phi=phi_rbf,\n",
    "                      action_list=action_list,\n",
    "                      n_episode=60,\n",
    "                      epsilon=0.0,\n",
    "                      epsilon_decay=1.0,\n",
    "                      gamma=gamma)\n",
    "\n",
    "pi_expert, stats = mdp_solver.solve()\n",
    "#plotting.plot_cost_to_go_mountain_car(env, pi_expert._estimator)\n",
    "plotting.plot_episode_stats(stats, smoothing_window=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearExpertPolicy():\n",
    "    \"\"\"\n",
    "    hard-coded near-optimal expert policy\n",
    "    for mountaincar-v0\n",
    "    \"\"\"\n",
    "    def choose_action(self, s):\n",
    "        pos, v = s\n",
    "        return 0 if v <=0 else 2\n",
    "pi = NearExpertPolicy()\n",
    "\n",
    "\n",
    "#pi = RandomPolicy2(action_list)\n",
    "D, stats = sim.simulate(pi=pi_expert, n_trial=1, n_episode=30, return_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_cost_to_go_mountain_car(env, pi_irl._estimator)\n",
    "#plot_episode_stats(stZts, smoothing_window=5)\n",
    "#dir(Simulator.to_matrix)\n",
    "plot_trajectory_mountain_car(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_mountain_car_linear(p, phi, gamma, precision, eps, D):\n",
    "    W_0 = np.random.rand(p)\n",
    "    lspi = LSPI(D=D,\n",
    "                action_list=action_list,\n",
    "                p=p,\n",
    "                phi=phi,\n",
    "                gamma=gamma,\n",
    "                precision=precision,\n",
    "                eps=eps,\n",
    "                W_0=W_0,\n",
    "                reward_fn=None)\n",
    "\n",
    "    W = lspi.solve()\n",
    "    return W\n",
    "    \n",
    "def solve_mountain_car_rbf(p, phi, gamma, precision, eps, D):  \n",
    "    W_0 = np.random.rand(p)\n",
    "    lspi = LSPI(D=D,\n",
    "                action_list=action_list,\n",
    "                p=p,\n",
    "                phi=phi,\n",
    "                gamma=gamma,\n",
    "                precision=precision,\n",
    "                eps=eps,\n",
    "                W_0=W_0,\n",
    "                reward_fn=None)\n",
    "\n",
    "    W = lspi.solve()\n",
    "    return W\n",
    "\n",
    "D = Simulator.to_matrix(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"batch data size {}\".format(D.shape))\n",
    "#W_linear = solve_mountain_car_linear(p_linear, phi_linear, gamma, precision, eps, D)\n",
    "W_rbf = solve_mountain_car_rbf(p_rbf, phi_rbf, gamma, precision, eps, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phi = phi_rbf\n",
    "phi = phi_linear\n",
    "pi_star = LinearQ2(action_list=action_list, phi=phi, W=W_linear)\n",
    "D_star, stats = sim.simulate(pi=pi, n_trial=1, n_episode=50, return_stats=True)\n",
    "plot_trajectory_mountain_car(D_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
